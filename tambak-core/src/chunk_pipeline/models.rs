//! This is the single source of truth for all type transformations. The Plan is
//! generated by the Planner and executed faithfully by the Executor.

use crate::types::TambakDataType;
use serde::{Deserialize, Serialize};

/// The top-level container for a complete, multi-stage compression plan.
/// It is serialized to JSON and stored in the final artifact.
#[derive(Serialize, Deserialize, Debug)]
pub struct ChunkPlan {
    /// Semantic version of the plan format; incremented when the JSON schema changes.
    pub plan_version: u32,
    /// The data type of the stream before any operations are applied.
    pub initial_type: TambakDataType,
    /// The sequence of operations to be executed. The type flow is derived from
    /// this sequence at runtime, not stored.
    pub pipeline: Vec<Operation>,
}

/// An enum representing all possible operations (both linear and meta) in a pipeline.
/// This structure is serialized to and from JSON using serde's tagged enum representation,
/// fulfilling the serialization contract.
#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, Eq, PartialOrd, Ord)] 
#[serde(tag = "op", content = "params")]
pub enum Operation {
    // --- Normalization & Type Conversion ---
    CanonicalizeZeros,
    BitCast {
        to_type: TambakDataType,
    },

    // --- Value Reduction ---
    Delta {
        order: usize,
    },
    XorDelta,

    // --- Sparsity & Repetition ---
    Rle,
    Dictionary,

    // --- Bit-Width Reduction ---
    ZigZag,
    Leb128,
    BitPack {
        bit_width: u8,
    },

    // --- Byte-level & Entropy ---
    Shuffle,
    Zstd {
        level: i32,
    },
    Ans,

    // --- Meta Operations with Sub-pipelines ---
    Sparsify {
        mask_stream_id: String,
        mask_pipeline: Vec<Operation>,
        values_pipeline: Vec<Operation>,
    },
    ExtractNulls {
        output_stream_id: String,
        null_mask_pipeline: Vec<Operation>,
    },
}

// /// Defines the strategy used by the empirical planner to select the best pipeline.
// ///
// /// This allows tuning the trade-off between planning speed and compression accuracy.
// #[derive(Debug, Clone, Copy, PartialEq, Eq)]
// pub enum PlannerStrategy {
//     /// **(Default)** Evaluates all candidates on a small sample, then runs a
//     /// full-data evaluation on the top N contenders to make the final choice.
//     /// This offers the best balance of accuracy and speed.
//     TopNFull {
//         /// The number of top candidates to evaluate on the full dataset.
//         top_n: usize,
//     },
//     /// A fast, two-stage sampling approach. Useful when full-data evaluation is
//     /// too slow. The final decision is still based on a sample.
//     TwoStageSample {
//         /// The size of the initial sample for broad pruning.
//         small_sample_size: usize,
//         /// The size of the larger sample for evaluating the top contenders.
//         large_sample_size: usize,
//     },
//     /// The fastest, least accurate strategy. It picks the best pipeline based
//     /// on a single, small sample. Prone to misprediction but useful for
//     /// maximum speed where planning time is critical.
//     Quick {
//         /// The size of the sample to use.
//         sample_size: usize,
//     },
// }

// // Provide a sensible default strategy. This is highly idiomatic.
// impl Default for PlannerStrategy {
//     fn default() -> Self {
//         PlannerStrategy::TopNFull { top_n: 3 }
//     }
// }

// /// Configuration for the entire pipeline planning process.
// ///
// /// This struct provides high-level control over which operations are considered
// /// and how the planner evaluates them, allowing for deep customization of the
// /// compression strategy. Using the builder pattern makes it easy to construct.
// #[derive(Debug, Clone)]
// pub struct PlannerConfig {
//     /// The strategy for evaluating and selecting the best pipeline.
//     pub strategy: PlannerStrategy,

//     /// The final entropy coders to append to every pipeline candidate.
//     /// This list is required and must not be empty.
//     pub entropy_coders: Vec<Operation>,
//     // NOTE: `core_transforms` and `terminal_transforms` are left out for now
//     // to keep the initial implementation simple.
//     // They can be added here later as `Option<Vec<...>>`.
// }

// impl PlannerConfig {
//     /// Creates a new PlannerConfig with a sensible, robust default configuration.
//     pub fn new() -> Self {
//         Self {
//             strategy: PlannerStrategy::default(), // Defaults to TopNFull { top_n: 3 }
//             entropy_coders: vec![Operation::Zstd { level: 3 }, Operation::Ans],
//         }
//     }

//     /// Overrides the default planner evaluation strategy.
//     ///
//     /// # Example
//     /// ```
//     /// // let config = PlannerConfig::new().with_strategy(PlannerStrategy::Quick { sample_size: 65536 });
//     /// ```
//     pub fn with_strategy(mut self, strategy: PlannerStrategy) -> Self {
//         self.strategy = strategy;
//         self
//     }

//     /// Overrides the list of entropy coders to test.
//     ///
//     /// # Panics
//     /// Panics if `coders` is empty or contains non-entropy operations.
//     pub fn with_entropy_coders(mut self, coders: Vec<Operation>) -> Self {
//         assert!(
//             !coders.is_empty(),
//             "Must provide at least one entropy coder."
//         );
//         assert!(
//             coders
//                 .iter()
//                 .all(|op| matches!(op, Operation::Zstd { .. } | Operation::Ans)),
//             "Invalid operation provided as an entropy coder. Only Zstd and Ans are supported."
//         );
//         self.entropy_coders = coders;
//         self
//     }
// }

// // Implement `Default` to make it easy to create a default config.
// impl Default for PlannerConfig {
//     fn default() -> Self {
//         Self::new()
//     }
// }
